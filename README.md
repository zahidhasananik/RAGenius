# Local RAG Assistant 

### ğŸ“‹ Prerequisites
- Install **Ollama** (ollama.com)
- Run `ollama pull llama3`

### âš™ï¸ Setup
1. Extract the ZIP.
2. Install dependencies: `pip install -r requirements.txt`
3. Create a `.env` file based on `.env.example`.

### ğŸš€ How to Run
1. **Indexing:** Run `python main.py` to process the sample files.
2. **API:** Run `uvicorn api:app --reload`.


### ğŸ“¡ API Endpoints
- `POST /upload`: Uploads .pdf, .docx, or .jpg.
- `POST /ask`: Takes a JSON `{"question": "..."}` and returns Answer + Context + Source.